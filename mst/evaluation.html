<!DOCTYPE HTML>
<!--
	Hyperspace by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>

<head>
	<title>Evaluation of Music Style Transfer methods</title>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
	<link rel="stylesheet" href="../assets/css/main.css" />
	<noscript>
		<link rel="stylesheet" href="../assets/css/noscript.css" />
	</noscript>
</head>

<body class="is-preload">
	<!-- Header -->
	<header id="header">
		<a href="../index.html" class="title">Music Style Transfer</a>
		<nav>
			<ul>
				<li><a href="../index.html">Home</a></li>
				<li><a href="introduction.html">Introduction</a></li>
				<li><a href="models.html">Models</a></li>
				<li><a href="experiments.html">Experiments</a></li>
				<li><a href="evaluation.html" class="active">Evaluation</a></li>
				<li><a href="listen.html">Listen</a></li>
				<li><a href="resources.html">Resources</a></li>
			</ul>
		</nav>
	</header>
	<!-- Wrapper -->
	<div id="wrapper">
		<!-- Main -->
		<section id="main" class="wrapper">
			<div class="inner">
				<h1 class="major">Evaluation Metrics</h1>
				<p>
					Building on top of <a href="https://zenodo.org/record/3527878">Cifka et al. (2020)</a> and <a
						href="https://aimc2021.iem.at/wp-content/uploads/2021/06/AIMC_2021_Lu_Dubnov.pdf">
						CycleGAN (Lu and Dubnov, 2021)</a>, four metrics were used to objectively evaluate the
					results of style transfer for the models trained.
					They can be separated into two categories: <b>content preservation</b> and <b>style fit</b>.
				</p>
				<h2 class="major">Content Preservation</h2>
				<p>
					Content preservation metrics provide a measure of content similarity between the original song and
					its style transfer counterpart. Two metrics are used for measuring preservation, the
					<i>Tonnetz distance</i> and the <i>frame-wise mean cosine similarity</i>.
				</p>
				<h3>Tonnetz Distance</h3>
				<p>
					Calculated as the L2 norm of the difference between the Tonnetz projection of a song and the
					Tonnetz projection of the transferred song. The Tonnetz projection of a song is obtained by
					computing the dot product between the song chromagram and the base Tonnetz graph.
				</p>
				<p>
					The Tonnetz graph is obtained by computing a set of coordinates for each tonal category (A to G#),
					across three different intervals (fifth, minor third and major third). The coordinates are given by
					the equation ($A$ and $w$ are defined for each interval):
					$$ C(x) \ =\ (\ A\times\sin(x\ \times\ w) ,\ A\times \cos(x\ \times\ w) \ ) $$
				</p>
				<h3>Frame-wise mean cosine similarity</h3>
				<img src="../images/evaluation/chroma_sim.png" class="image left">
				</br>
				<p>
					Given by the mean cosine similarity between averaged windows of the chromagram representation of
					the original song and the transferred song.
				</p>
				</br>
				</br>

				<p>
					Following the steps <a href="https://zenodo.org/record/3527878">Cifka et al. (2020)</a>, the
					chromagram of each song is computed at a rate of 12 frames per beat, then averaged over a
					sliding window of 24 frames (i.e. 2 beats) and a stride of 12 frames (1 beat).
					Next, the cosine similarity between the averaged windows of two songs are computed, and
					the overall mean is taken.
				</p>
				</br>
				<p>
					Both content preservation metrics are computed by measuring the similarity between the original
					songs and the style transfer result.
				</p>
				<h2 class="major">Style Fit</h2>
				<p>
					Style fit measures how well the transferred song fits the target genre, and the metrics used are
					<i>time-pitch difference</i> and <i>onset-duration</i>.
				</p>
				<img src="../images/evaluation/time-pitch-hist-pop.png" class="image right">
				<h3>Time-pitch difference</h3>
				<p>
					To compute the time-pitch metric, we create a set of pairs by taking the
					difference in the onset times and pitch, for all pairs of notes that are at most
					4 beats apart, and have difference in pitch of at most 20 semitones.
				</p>
				<p>
					A 2D histogram is created from these pairs with the onset differences in the x-axis and
					pitch differences in the y-axis. The histogram is flattened, creating a 1D vector which is then
					compared to a reference vector of the target genre by measuring the cosine similarity.
					$$ T \ = \{\ (start(b) - start(a),\ pitch(b) - pitch(a))\ |\ (a,b)\ \in\
					[0,4)\times\{-20,-19,...,20\},\ a\neq b \} $$
				</p>
				<h3>Onset-duration</h3>
				<img src="../images/evaluation/onset-duration-hist-jazz.png" class="image right">

				<p>
					We follow a similar procedure to the compute the onset duration metric.

					This time, the pairs
					consist of the note onsets (relative to the beat) and the note duration. Again a 2D histogram is
					computed, flattened and the cosine similarity is measured against a vector of the target style.
					$$ T \ = \{\ (start(a) \ mod 4,\ end(a) - start(a) )\ |\ a\ \in\ [0,4)\times[0,2)\} $$
				</p>
				<p>
					Style fit metrics were computed by measuring the similarity of the transferred songs
					against a reference profile of the original genre, which was generated by taking the
					mean of histograms computed for songs of the original genre. We call these <i>nano metrics.</i>
				</p>
				<p>
					<i>Macro style</i> metrics were also computed
					by measuring the similarity between the reference profile, and the mean of the
					histograms of the converted songs
				</p>
				<h1 class="major">Results</h1>
				<p>
					To ensure the models trained during experimentation could be compared against
					each other, each model was used to perform style transfer on the Bodhidharma
					dataset <a
						href="https://www.semanticscholar.org/paper/THE-BODHIDHARMA-SYSTEM-AND-THE-RESULTS-OF-THE-MIREX-McKay-Fujinaga/786585327692e7d592cdd5851295c45f597749ce">
						(Mckay and Fujinaga 2005).</a> For each model, we aggregated the results of the experiments and
					report distribution of scores in the images below.
				</p>
				<h3>Tonnetz Distance</h3>
				<img src="../images/results/chordgan_tonnetz_all.png" class="image left">
				<img src="../images/results/cyclegan_tonnetz_all.png" class="image right">
				<img src="../images/results/chordgan_nano_all.png" class="image">
				<img src="../images/results/cyclegan_nano_all.png" class="image">
				<img src="../images/results/chordgan_macro.png" class="image">
				<img src="../images/results/cyclegan_macro_all.png" class="image">

			</div>

		</section>

	</div>

	<!-- Footer -->
	<footer id="footer" class="wrapper alt">
		<div class="inner">
			<ul class="menu">
				<li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
			</ul>
		</div>
	</footer>

	<!-- Scripts -->
	<script src="../assets/js/jquery.min.js"></script>
	<script src="../assets/js/jquery.scrollex.min.js"></script>
	<script src="../assets/js/jquery.scrolly.min.js"></script>
	<script src="../assets/js/browser.min.js"></script>
	<script src="../assets/js/breakpoints.min.js"></script>
	<script src="../assets/js/util.js"></script>
	<script src="../assets/js/main.js"></script>
	<script type="text/javascript" src="http://math.etsu.edu/LaTeXMathML/LaTeXMathML.js"></script>


</body>

</html>