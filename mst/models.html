<!DOCTYPE HTML>
<!--
	Hyperspace by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>

<head>
	<title>Evaluation of Music Style Transfer methods</title>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
	<link rel="stylesheet" href="../assets/css/main.css" />
	<noscript>
		<link rel="stylesheet" href="../assets/css/noscript.css" />
	</noscript>
</head>

<body class="is-preload">

	<!-- Header -->
	<header id="header">
		<a href="../index.html" class="title">Music Style Transfer</a>
		<nav>
			<ul>
				<li><a href="../index.html">Home</a></li>
				<li><a href="introduction.html">Introduction</a></li>
				<li><a href="models.html" class="active">Models</a></li>
				<li><a href="experiments.html">Experiments</a></li>
				<li><a href="evaluation.html">Evaluation</a></li>
				<li><a href="listen.html">Listen</a></li>
				<li><a href="resources.html">Resources</a></li>
			</ul>
		</nav>
	</header>
	<!-- Wrapper -->
	<div id="wrapper">
		<!-- Main -->
		<section id="main" class="wrapper">
			<div class="inner">
				<h1 class="major">Models Evaluated</h1>
				<p>
					The models chosen for the experimentation and benchmark were <a
						href="https://aimc2021.iem.at/wp-content/uploads/2021/06/AIMC_2021_Lu_Dubnov.pdf">
						CycleGAN (Lu and Dubnov, 2021)</a> and <a href="https://arxiv.org/pdf/1809.07575.pdf">CycleGAN
						(Brunner, Wang, Wattenhofer and Zhao, 2018)</a>.
				</p>
				<h1 class="minor">CycleGAN</h1>
				<figure>
					<img src="../images/models/cyclegan_arch.png" class="image fit" alt="CycleGAN architecture" />
					<figcaption>CycleGAN architecture <a href="https://arxiv.org/pdf/1809.07575.pdf">CycleGAN
							(Brunner, Wang, Wattenhofer and Zhao, 2018)</a></figcaption>
				</figure></br>
				<p>
					The CycleGAN approach follows the successful architecture proposed by <a
						href="https://arxiv.org/pdf/1703.10593.pdf">(Zhu, J. Y. et al. , 2017)</a>. As the name implies,
					The model is a Generative Adversarial Network and the core idea behind it is that style transfer is
					cyclical, that is, converting a song from genre A to genre B and then back to A, should yield the
					original input. They use a deep architecture with applying various convolutions with instance
					normalization in order to stabilize training, and defining custom losses for each generator as well
					as a combined cycle loss.
				</p>
				<p>
					While the original code was developed in TensorFlow 1 was provided, no dependencies or documentation
					was provided. The authors also made an attempt to convert the model to TensorFlow 2 but again, no
					dependencies were specified and very little was left in the way of documentation, which made it a
					difficult model to reproduce.
				</p>
				<p>
					These issues are addressed in the <a
						href="https://github.com/amaralcs/tf-cyclegan-music-style-transfer">provided implementation</a>,
					where the refactored code is well documented and dependencies are clearly specified.
					In addition, we use the TensorFlow dataset format for saving the data, which allowed for a slight
					improvement in performance and increased batch size.
				</p>
				<h1 class="minor">ChordGAN</h1>


				<img src="../images/models/chroma_example.png" id="chroma-example" />
				<p>
					In contrast, the architecture employed by ChordGAN is relatively simple with discriminator and
					generators that use only dense layers and are shallow. The main innovation in this approach is
					that the generator takes the chromagram representation of the song as input and is trained to
					generate the MIDI representation.
				</p>
				<p>
					Again, the original codebase was not well documented and developed using TensorFlow 1. In
					addition
					many of the preprocessing steps happened in parallel with training, which obfuscated the model
					implementation.
					We made improvements to the documentation, delineated data preparation and model training and
					provide scripts for automating training and evaluation.
				</p>
				<div style="clear: right">
					<figcaption id="right-caption">
						Chromagram representation of A Touch of Blues
					</figcaption>
				</div>
				</br>
				</br>




			</div>
		</section>

	</div>

	<!-- Footer -->
	<footer id=" footer" class="wrapper alt">
		<div class="inner">
			<ul class="menu">
				<li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
			</ul>
		</div>
	</footer>

	<!-- Scripts -->
	<script src="../assets/js/jquery.min.js"></script>
	<script src="../assets/js/jquery.scrollex.min.js"></script>
	<script src="../assets/js/jquery.scrolly.min.js"></script>
	<script src="../assets/js/browser.min.js"></script>
	<script src="../assets/js/breakpoints.min.js"></script>
	<script src="../assets/js/util.js"></script>
	<script src="../assets/js/main.js"></script>

</body>

</html>